###<h2 align="center">Toxic Comment Classification</h2>
A project aimed at improving online conversation quality by developing a model to accurately detect various types of toxicity in comments, such as threats, obscenity, insults, and identity-based hate, built using machine learning and natural language processing techniques.

# Dataset: 
The data can be downloaded from Kaggle using the below links:
*Disclaimer: the dataset for this contains text that may be considered profane, vulgar, or offensive.*
1. [Training dataset](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data?select=train.csv.zip)
2. [Test dataset](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data?select=test.csv.zip)
