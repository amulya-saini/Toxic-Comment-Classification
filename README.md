<h1 align="center">Toxic Comment Classification</h1>
A project aimed at improving online conversation quality by developing a model to accurately detect various types of toxicity in comments, such as threats, obscenity, insults, and identity-based hate, built using machine learning and natural language processing techniques.

## Dataset: 

*Disclaimer: the dataset for this contains text that may be considered profane, vulgar, or offensive.*

The data can be downloaded from Kaggle using the below links:

1. [Training dataset](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data?select=train.csv.zip)
2. [Test dataset](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data?select=test.csv.zip)
