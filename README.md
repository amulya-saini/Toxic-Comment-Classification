<h1 align="center">Toxic Comment Classification</h1>
A project aimed at improving online conversation quality by developing a model to accurately detect various types of toxicity in comments, such as threats, obscenity, insults, and identity-based hate. Built using machine learning and natural language processing techniques.

## Dataset: 

*Disclaimer: the dataset for this contains text that may be considered profane, vulgar, or offensive.*

The data can be downloaded from Kaggle using the below links:

1. [Training dataset](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data?select=train.csv.zip)
2. [Test dataset](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data?select=test.csv.zip)

## Packages Used

The project makes use of various Python packages for data manipulation, analysis, visualization, natural language processing, feature extraction, model evaluation, dimensionality reduction, regression modeling, and deep learning. Here is a list of the main packages used:

- **Data Manipulation and Analysis:**
  - NumPy
  - SciPy
  - Pandas

- **String Manipulation:**
  - re
  - string

- **Data Visualization:**
  - Matplotlib
  - Seaborn

- **Natural Language Processing (NLP) and Text Processing:**
  - NLTK
  - WordCloud
  - Gensim

- **Text Processing Feature Extraction:**
  - TF-IDF Vectorizer
  - Count Vectorizer

- **Data Splitting and Model Evaluation:**
  - Scikit-learn (sklearn)

- **Dimensionality Reduction:**
  - TruncatedSVD
  - PCA

- **Regression Models:**
  - Stochastic Gradient Descent (SGD) Regressor
  - Decision Tree Regressor

- **Deep Learning and Neural Networks:**
  - TensorFlow
  - Keras

Please note that some packages may require additional installation steps using `pip install <package_name>`.
